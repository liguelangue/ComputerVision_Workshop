{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Loading Images\n",
    "img = cv2.imread(\"flower.png\")\n",
    "gray_img = cv2.imread(\"flower.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Load two images\n",
    "image1_bgr = cv2.imread('seal.png')\n",
    "image1 = cv2.imread('seal.png', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('wordmark.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harris Corner Detection\n",
    "gray_hcd = np.float32(gray_img)\n",
    "harris_corners = cv2.cornerHarris(gray_hcd, blockSize=20, ksize=3, k=0.04)\n",
    "# Dilate the detected cornors to enhance them\n",
    "harris_corners = cv2.dilate(harris_corners, None)\n",
    "# Threshold for an optimal value\n",
    "img_hcd = img.copy()\n",
    "img_hcd[harris_corners > 0.01*harris_corners.max()] = [0, 0, 255]\n",
    "\n",
    "cv2.imshow(\"harris corners flower\", img_hcd)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Harris Corner Detection\n",
    "gray_hcd1 = np.float32(image1)\n",
    "harris_corners1 = cv2.cornerHarris(gray_hcd1, blockSize=20, ksize=3, k=0.04)\n",
    "harris_corners1 = cv2.dilate(harris_corners1, None)\n",
    "img_hcd1 = image1_bgr.copy()\n",
    "img_hcd1[harris_corners1 > 0.01*harris_corners1.max()] = [0, 0, 255]\n",
    "\n",
    "cv2.imshow(\"harris corners seal\", img_hcd1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT Detector\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "# Draw Keypoints\n",
    "image_with_keypoints = cv2.drawKeypoints(img, keypoints, None, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"SIFT keypoints\", image_with_keypoints)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT Detector\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "# FLANN Matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Apply ratio test as per Lowe's paper\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Draw matches\n",
    "result = cv2.drawMatches(image1, keypoints1, image2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Show the matching result\n",
    "cv2.imshow('Feature Matching', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
